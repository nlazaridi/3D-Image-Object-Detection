{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Script to convert GLB to OBJ with trimesh library\n",
    "\n",
    "Try to solve the issue with the texture by using several ways. None of them, worked\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import os\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from trimesh.transformations import scale_matrix, translation_matrix\n",
    "from pytorch3d.io import load_obj, save_obj, load_ply,load_objs_as_meshes\n",
    "import torch\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytorch3d.structures import Meshes\n",
    "import re\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    FoVOrthographicCameras,\n",
    "    Materials,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    TexturesVertex,\n",
    "    TexturesAtlas,\n",
    "    Textures,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRasterizer\n",
    ")\n",
    "\n",
    "from pytorch3d.structures.meshes import (\n",
    "    Meshes,\n",
    "    join_meshes_as_batch,\n",
    "    join_meshes_as_scene,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import os\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from trimesh.transformations import scale_matrix, translation_matrix\n",
    "from pytorch3d.io import load_obj, save_obj, load_ply,load_objs_as_meshes\n",
    "import pytorch3d\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    FoVOrthographicCameras,\n",
    "    Materials,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    PointLights,\n",
    "    SoftPhongShader,\n",
    "    TexturesVertex,\n",
    "    HardPhongShader,\n",
    "    Textures,\n",
    "    TexturesUV,\n",
    "    TexturesAtlas,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRasterizer\n",
    ")\n",
    "\n",
    "\n",
    "from pytorch3d.structures import Meshes\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from rendererClass import RendererClass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import itertools\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimesh: Export as OBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Summary of the results:\n",
    "If we have one geometry it works smoothly (both for mesh and scene) --> Astronaut for instance works perfect\n",
    "If there are several geometries, as mesh stores only the OBJ and as scene OBJ + mtl but not texture\n",
    "So when importing with load_obj it gives error! \n",
    "solution: Work without textures for now\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLB_toOBJ(path_GLB, force_to = \"mesh\",save_name = None):\n",
    "    \n",
    "    logger.info(f\"Loading from {path_GLB}\")\n",
    "    mesh = trimesh.load(path_GLB, force = force_to)\n",
    "    \n",
    "    \n",
    "    #scene = trimesh.load(path_astronaut,force = force_to).dump()\n",
    "    #combined = trimesh.util.concatenate(scene)\n",
    "    #combined.export(save_path,include_texture=True)\n",
    "\n",
    "    \n",
    "    if save_name:\n",
    "        \n",
    "        path = Path(path_GLB).parent.absolute()\n",
    "        \n",
    "        save_path = os.path.join(path,force_to)\n",
    "        os.mkdir(save_path) if not os.path.exists(save_path) else None\n",
    "        logger.info(f'Save results to file: {save_path}')\n",
    "        mesh.export(file_type=\"obj\",\n",
    "                    #resolver = trimesh.resolvers.nearby_names(save_path),\n",
    "                    write_texture = True,\n",
    "                    file_obj = os.path.join(save_path,save_name),\n",
    "                    include_color=True,\n",
    "                    include_texture=True)\n",
    "        \n",
    "        \n",
    "    mesh_obj, textures = trimesh.exchange.obj.export_obj(mesh, return_texture=True)\n",
    "    return mesh, mesh_obj, textures\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bed = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Bed/Single_Bed.gltf\"\n",
    "path_liberty = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Liberty/Liberty_v4.glb\"\n",
    "path_astronaut = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Astronaut/Astronaut.glb\"\n",
    "part_kitchen = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Kitchen/GLB_format/kitchen.glb\"\n",
    "path_banana = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Banana/banana.glb\"\n",
    "bottle = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/bottle/WaterBottle.glb\"\n",
    "path_apple = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Apple/apples.gltf\"\n",
    "parth_kitchen_2 = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/kitchen_v2/kitchen.glb\"\n",
    "path_ship_2 = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/ship_v2/uploads_files_2901006_ship.glb\"\n",
    "path_girl = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/girl/girl.glb\"\n",
    "force_to = \"scene\"\n",
    "save_name = \"GLB_to_OBJ_force_\" + force_to +\".obj\"\n",
    "\n",
    "mesh_trimesh, mesh_obj, textures = GLB_toOBJ(path_girl,force_to,save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_to = \"scene\"\n",
    "save_name = \"GLB_to_OBJ_force_\" + force_to +\".obj\"\n",
    "path = Path(path_liberty).parent.absolute()\n",
    "save_path = os.path.join(path,force_to,save_name)\n",
    "print(save_path)\n",
    "\n",
    "#load it back as obj \n",
    "try:\n",
    "        verts, faces, aux = load_obj(\n",
    "                save_path,\n",
    "                device=\"cpu\",\n",
    "                load_textures=True,\n",
    "                create_texture_atlas=True,\n",
    "                texture_atlas_size=4,\n",
    "                texture_wrap=\"repeat\"\n",
    "                )\n",
    "except:\n",
    "        print(\"An exception occur\")\n",
    "        verts, faces, aux = load_obj(\n",
    "        save_path,\n",
    "        device=\"cpu\",\n",
    "        load_textures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andstasi/anaconda3/envs/triton_inf/lib/python3.8/site-packages/pytorch3d/io/utils.py:66: UserWarning: Faces have invalid indices\n",
      "  warnings.warn(\"Faces have invalid indices\")\n"
     ]
    }
   ],
   "source": [
    "verts, faces, aux = load_obj(\n",
    "            save_path,\n",
    "            device=\"cpu\",\n",
    "            load_textures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Obj to Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The issue is that even if we load it as a obj and export it as obj, the output is wrong....\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "specified material ((null))  not loaded!\n"
     ]
    }
   ],
   "source": [
    "scene_path = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Kitchen/GLB_format/Initial_scene/uploads_files_2550510_kitchen.obj\"\n",
    "\n",
    "scene = trimesh.load(scene_path, process=False,maintain_order=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.export(os.path.join(Path(scene_path).parent.absolute(),'back_to_obj.obj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_obj = trimesh.load(os.path.join(Path(scene_path).parent.absolute(),'back_to_obj.obj'), process=False,maintain_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the scene as a several meshes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_kitchen = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Kitchen/GLB_format/uploads_files_2550510_kitchen.obj\"\n",
    "glb_kitchen = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Kitchen/GLB_format/kitchen.glb\"\n",
    "path_apple = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Apple/apples.gltf\"\n",
    "path_liberty = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Liberty/Liberty_v4.glb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n",
      "primitive has no mode! trying GL_TRIANGLES?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scene = trimesh.load(path_liberty)\n",
    "\n",
    "include_texture = True\n",
    "\n",
    "save_path_init = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Liberty/merge_mesh_example\"\n",
    "\n",
    "\n",
    "for key,mesh in scene.geometry.items():\n",
    "    \n",
    "    save_path = os.path.join(save_path_init,re.sub(r'[^\\w]', '', key))\n",
    "    os.mkdir(save_path) if not os.path.exists(save_path) else None\n",
    "    '''if include_texture and len(np.shape(getattr(mesh.visual, 'uv', None))) == 2:\n",
    "        material = mesh.visual.material\n",
    "    \n",
    "    if hasattr(material, 'to_simple'):\n",
    "        material = material.to_simple()'''\n",
    "    \n",
    "    \n",
    "    mesh.export(write_texture = True,\n",
    "                    file_obj = os.path.join(save_path,\"kitchen\" + key + \".obj\"),\n",
    "                    include_color=True,\n",
    "                    include_texture=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the obj ext\n",
    "obj_files = []\n",
    "for path in glob(os.path.join(save_path_init,\"*/\"), recursive = True):\n",
    "    obj_files.append(glob(os.path.join(path,\"*.obj\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import them again from the object\n",
    "all_meshes = []\n",
    "\n",
    "for mesh_file in obj_files:\n",
    "    \n",
    "    print(mesh_file)\n",
    "    if mesh_file == '/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/data/random_example/Liberty/merge_mesh_example/Athenea001/kitchenAthenea.001.obj': \n",
    "        pass\n",
    "    else:\n",
    "        all_meshes.append(load_objs_as_meshes(mesh_file, device=device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = join_meshes_as_scene(all_meshes, include_textures = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"/home/andstasi/Projects/MediaVerse/3D_to_2D_converter/pytorch3d-renderer/params_inference.json\"\n",
    "with open(param_path) as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "#load the pars to render 3D\n",
    "all_dist = params[\"camera_dist\"]\n",
    "all_elev = params[\"elevation\"]\n",
    "all_azim = params[\"azim_angle\"]\n",
    "\n",
    "#get all combinations\n",
    "all_combs =  list(itertools.product(*[all_dist,all_elev,all_azim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist,elev,azim = all_combs[0]\n",
    "image_size = 1024\n",
    "\n",
    "R, T = look_at_view_transform(dist=100, elev=elev, azim=azim)\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=image_size,\n",
    "    blur_radius=0.0,\n",
    "    clip_barycentric_coords=True,\n",
    "    faces_per_pixel=1,\n",
    ")\n",
    "# Initialize rasterizer by using a MeshRasterizer class\n",
    "rasterizer = MeshRasterizer(\n",
    "    cameras=cameras,\n",
    "    raster_settings=raster_settings\n",
    ")\n",
    "# The textured phong shader interpolates the texture uv coordinates for\n",
    "# each vertex, and samples from a texture image.\n",
    "shader = HardPhongShader(device=device, cameras=cameras,lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]]))\n",
    "\n",
    "# Create a mesh renderer by composing a rasterizer and a shader\n",
    "renderer = MeshRenderer(rasterizer, shader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = torch.ones(1, mesh.verts_list()[0].shape[0], 3, device=device)\n",
    "#features = torch.from_numpy(np.array(aux.texture_images.values(),dtype='float32'))[None]\n",
    "mesh.textures = TexturesVertex(verts_features=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = renderer(mesh.extend(1))[0, ..., :3].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb3aa10cdef9f65946eadaea8cfe9157d932ff8335895c9f38c75282049245de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('triton_inf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
